#coding=utf8
import argparse
import lasagne
import numpy as np
import theano
import theano.tensor as T
from sklearn.preprocessing import LabelBinarizer,label_binarize

def get_dataset(dimention):
    x=np.random.random((10000,dimention))
    y=np.zeros((10000))
    for i in enumerate(x):
        y=int(i[0]/0.1)
    return x,y

class Model:
    def __init__(self,dimension=50,n_classes=10,batch_size=32,n_epoch=50,path_length=10,
                 n_paths=1000,max_norm=50,lr=0.05,update_method='sgd',std=0.5,**kwargs):
        self.dimension=dimension
        self.n_classe=n_classes
        self.n_slot=n_classes
        self.batch_size=batch_size
        self.n_epoch=n_epoch
        self.path_length=path_length
        self.n_paths=n_paths
        self.max_norm=max_norm
        self.lr=lr
        self.std=std

        if update_method=='sgd':
            self.update_method=lasagne.updates.sgd
        elif update_method=='adagrad':
            self.update_method=lasagne.updates.adagrad
        elif update_method=='adadelta':
            self.update_method=lasagne.updates.adadelta
        elif update_method=='rmsprop':
            self.update_method=lasagne.updates.rmsprop
        
    def build(self):
        x_range=T.tensor3()
        x_action=T.tensor3()
        x_reward=T.vector()

        x_range_shared=theano.shared(np.zeros((self.batch_size,self.path_length,self.dimension),dtype=theano.config.floatX),borrow=True)
        x_range_action=theano.shared(np.zeros((self.batch_size,self.path_length,self.n_classes),dtype=theano.config.floatX),borrow=True)
        x_range_reward=theano.shared(np.zeros(self.batch_size,dtype=theano.config.floatX),borrow=True)
        x_range_memory=theano.shared(np.zeros((self.batch_size,self.path_length,self.n_classes,self.dimension),dtype=theano.config.floatX),borrow=True)

        '''前期的框架模型，主要是得到x到h的映射，以及memory的构建'''
        D1, D2 = lasagne.init.Normal(std=0.1), lasagne.init.Normal(std=0.1)
        l_range_in = lasagne.layers.InputLayer(shape=(self.batch_size,self.path_length,self.dimension))
        l_range_flatten = lasagne.layers.ReshapeLayer(l_range_in,[self.batch_size*self.path_length,self.dimension])
        l_range_dense1 = lasagne.layers.DenseLayer(l_range_flatten,self.dimension,W=D1,nonlinearity=lasagne.nonlinearities.sigmoid)
        l_range_dense2 = lasagne.layers.DenseLayer(l_range_dense1,self.dimension,W=D2,nonlinearity=lasagne.nonlinearities.sigmoid)
        l_range_hidden=lasagne.layers.ReshapeLayer(l_range_dense2,[self.batch_size*self.path_length,1,self.dimension]) #[bs*path_length,dimension]
        # l_range_mu = lasagne.layers.DenseLayer(l_range_hidden,self.n_slot,W=D2,nonlinearity=lasagne.nonlinearities.softmax)

        '''Policy Gradient Methods的模型，主要是从Memory状态得到action的概率'''
        l_range_memory_in = lasagne.layers.InputLayer(shape=(self.batch_size,self.path_length,self.n_classe,self.dimension))
        l_range_memory = lasagne.layers.ReshapeLayer(l_range_in,[self.batch_size*self.path_length,self.n_classe,self.dimension])
        l_range_status=lasagne.layers.ConcatLayer((l_range_memory,l_range_hidden),axis=1)

        '''模型的总体参数和更新策略等'''
        l_range_mu = lasagne.layers.ReshapeLayer(l_range_dense2,[self.batch_size,self.path_length,self.n_classes])
        probas_range = lasagne.layers.helper.get_output(l_range_mu, {l_range_in: x_range_shared})
        params=lasagne.layers.helper.get_all_params(l_range_mu,trainable=True)
        givens = {
            x_range: x_range_shared,
            x_action: x_range_action,
            x_reward:x_range_reward
        }
        cost=-T.mean(T.sum(T.sum(T.log(probas_range)*x_action,axis=2),axis=1)*x_reward)
        grads=T.grad(cost,params)
        scaled_grads = lasagne.updates.total_norm_constraint(grads, self.max_norm)
        updates = lasagne.updates.adagrad(scaled_grads, params, learning_rate=self.lr)

        output_model_range = theano.function([],[probas_range,cost],givens=givens,updates=updates,on_unused_input='ignore',allow_input_downcast=True)
        pass


if __name__=='__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--task', type=int, default=1, help='Task#')
    parser.add_argument('--dimension', type=int, default=50, help='Dimension#')
    parser.add_argument('--n_classes', type=int, default=10, help='Task#')
    parser.add_argument('--batch_size', type=int, default=16, help='Task#')
    parser.add_argument('--n_epoch', type=int, default=50, help='Task#')
    parser.add_argument('--path_length', type=int, default=10, help='Task#')
    parser.add_argument('--n_paths', type=int, default=1000, help='Task#')
    parser.add_argument('--max_norm', type=float, default=50, help='Task#')
    parser.add_argument('--lr', type=float, default=0.05, help='Task#')
    parser.add_argument('--std', type=float, default=0.5, help='Task#')
    parser.add_argument('--update_method', type=str, default='sgd', help='Task#')
    args=parser.parse_args()
    print '*' * 80
    print 'args:', args
    print '*' * 80
    model=Model(**args.__dict__)
    model.train()
